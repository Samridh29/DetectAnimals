{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h1>Detecting Animals</h1>\n","\n","<h2>Imporing Libaries</h2>"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import matplotlib\n","matplotlib.use(\"Agg\")\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import SGD\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import random\n","import pickle\n","import cv2"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Getting the data</h2>"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["data =[]\n","labels = []\n","\n","image_paths = sorted(list(paths.list_images(\"./animals\")))\n","random.seed(42)\n","random.shuffle(image_paths)\n","\n","for imgpath in image_paths:\n","    #Loading the image, resizing it to a fixed size and then flattening it\n","    image = cv2.imread(imgpath)\n","    image = cv2.resize(image, (32, 32)).flatten()\n","    data.append(image)\n","    #Getting the labels and appending them to the labels list\n","    label = imgpath.split(os.path.sep)[-2]\n","    labels.append(label)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["data = np.array(data, dtype='float')/255.0\n","labels = np.array(labels)\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Spliting the data into train and test sets</h2>"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["(train_X, test_X, train_Y, test_Y) = train_test_split(data, labels, test_size=0.25, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Performing one-hot encodings</h2>"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["lb = LabelBinarizer()\n","train_Y = lb.fit_transform(train_Y)\n","test_Y = lb.transform(test_Y)"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Defining the model</h2> "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["model = Sequential()\n","model.add(Dense(1024, input_shape=(3072,) , activation=\"sigmoid\"))\n","model.add(Dense(512, activation = 'sigmoid'))\n","model.add(Dense(len(lb.classes_), activation = 'softmax'))"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Compiling</h2>"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["opt = SGD(learning_rate = 0.01)\n","model.compile(loss=\"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Fitting the data</h2>"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","71/71 [==============================] - 2s 15ms/step - loss: 1.1034 - accuracy: 0.3316 - val_loss: 1.1243 - val_accuracy: 0.3147\n","Epoch 2/100\n","71/71 [==============================] - 1s 10ms/step - loss: 1.0850 - accuracy: 0.3804 - val_loss: 1.1222 - val_accuracy: 0.3147\n","Epoch 3/100\n","71/71 [==============================] - 1s 7ms/step - loss: 1.0776 - accuracy: 0.3929 - val_loss: 1.0552 - val_accuracy: 0.3853\n","Epoch 4/100\n","71/71 [==============================] - 1s 8ms/step - loss: 1.0566 - accuracy: 0.4484 - val_loss: 1.0662 - val_accuracy: 0.3733\n","Epoch 5/100\n","71/71 [==============================] - 1s 8ms/step - loss: 1.0431 - accuracy: 0.4502 - val_loss: 1.0985 - val_accuracy: 0.3147\n","Epoch 6/100\n","71/71 [==============================] - 1s 7ms/step - loss: 1.0311 - accuracy: 0.4813 - val_loss: 1.0854 - val_accuracy: 0.3253\n","Epoch 7/100\n","71/71 [==============================] - 1s 8ms/step - loss: 1.0182 - accuracy: 0.4831 - val_loss: 0.9939 - val_accuracy: 0.5453\n","Epoch 8/100\n","71/71 [==============================] - 1s 7ms/step - loss: 1.0039 - accuracy: 0.5018 - val_loss: 0.9940 - val_accuracy: 0.4907\n","Epoch 9/100\n","71/71 [==============================] - 1s 7ms/step - loss: 0.9939 - accuracy: 0.4978 - val_loss: 1.0268 - val_accuracy: 0.4787\n","Epoch 10/100\n","71/71 [==============================] - 1s 10ms/step - loss: 0.9761 - accuracy: 0.5142 - val_loss: 0.9599 - val_accuracy: 0.5293\n","Epoch 11/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.9661 - accuracy: 0.5124 - val_loss: 1.0399 - val_accuracy: 0.4173\n","Epoch 12/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.9497 - accuracy: 0.5302 - val_loss: 0.9502 - val_accuracy: 0.5293\n","Epoch 13/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.9376 - accuracy: 0.5284 - val_loss: 0.9230 - val_accuracy: 0.5480\n","Epoch 14/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.9315 - accuracy: 0.5298 - val_loss: 0.9545 - val_accuracy: 0.5000\n","Epoch 15/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.9236 - accuracy: 0.5378 - val_loss: 0.9077 - val_accuracy: 0.5347\n","Epoch 16/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.9065 - accuracy: 0.5480 - val_loss: 0.8988 - val_accuracy: 0.5347\n","Epoch 17/100\n","71/71 [==============================] - 1s 10ms/step - loss: 0.9000 - accuracy: 0.5587 - val_loss: 0.8859 - val_accuracy: 0.5933\n","Epoch 18/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8950 - accuracy: 0.5453 - val_loss: 0.8943 - val_accuracy: 0.5453\n","Epoch 19/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8920 - accuracy: 0.5440 - val_loss: 0.8908 - val_accuracy: 0.5920\n","Epoch 20/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8846 - accuracy: 0.5520 - val_loss: 0.8712 - val_accuracy: 0.6053\n","Epoch 21/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8828 - accuracy: 0.5364 - val_loss: 0.9267 - val_accuracy: 0.5333\n","Epoch 22/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8702 - accuracy: 0.5587 - val_loss: 0.8699 - val_accuracy: 0.5600\n","Epoch 23/100\n","71/71 [==============================] - 1s 10ms/step - loss: 0.8688 - accuracy: 0.5462 - val_loss: 1.0510 - val_accuracy: 0.4520\n","Epoch 24/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8660 - accuracy: 0.5591 - val_loss: 0.8517 - val_accuracy: 0.6107\n","Epoch 25/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8573 - accuracy: 0.5573 - val_loss: 0.9036 - val_accuracy: 0.5267\n","Epoch 26/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8576 - accuracy: 0.5604 - val_loss: 0.8651 - val_accuracy: 0.5587\n","Epoch 27/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8525 - accuracy: 0.5458 - val_loss: 0.8532 - val_accuracy: 0.5573\n","Epoch 28/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8547 - accuracy: 0.5560 - val_loss: 0.8505 - val_accuracy: 0.6000\n","Epoch 29/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8437 - accuracy: 0.5644 - val_loss: 0.9744 - val_accuracy: 0.4813\n","Epoch 30/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8446 - accuracy: 0.5693 - val_loss: 0.8419 - val_accuracy: 0.5800\n","Epoch 31/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8431 - accuracy: 0.5684 - val_loss: 0.9494 - val_accuracy: 0.5000\n","Epoch 32/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8402 - accuracy: 0.5707 - val_loss: 0.8340 - val_accuracy: 0.6040\n","Epoch 33/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8351 - accuracy: 0.5738 - val_loss: 0.8561 - val_accuracy: 0.5440\n","Epoch 34/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8353 - accuracy: 0.5676 - val_loss: 0.8583 - val_accuracy: 0.5720\n","Epoch 35/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8331 - accuracy: 0.5680 - val_loss: 0.8523 - val_accuracy: 0.5800\n","Epoch 36/100\n","71/71 [==============================] - 1s 10ms/step - loss: 0.8280 - accuracy: 0.5827 - val_loss: 0.8426 - val_accuracy: 0.6027\n","Epoch 37/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8292 - accuracy: 0.5796 - val_loss: 0.8481 - val_accuracy: 0.5973\n","Epoch 38/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8329 - accuracy: 0.5693 - val_loss: 0.8290 - val_accuracy: 0.6187\n","Epoch 39/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8267 - accuracy: 0.5733 - val_loss: 0.8319 - val_accuracy: 0.6040\n","Epoch 40/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8174 - accuracy: 0.5840 - val_loss: 0.8665 - val_accuracy: 0.5427\n","Epoch 41/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8238 - accuracy: 0.5791 - val_loss: 0.8622 - val_accuracy: 0.5467\n","Epoch 42/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8186 - accuracy: 0.5782 - val_loss: 0.8349 - val_accuracy: 0.5773\n","Epoch 43/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8191 - accuracy: 0.5871 - val_loss: 0.9105 - val_accuracy: 0.5160\n","Epoch 44/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8170 - accuracy: 0.5822 - val_loss: 0.8326 - val_accuracy: 0.5760\n","Epoch 45/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8138 - accuracy: 0.5800 - val_loss: 0.8644 - val_accuracy: 0.5720\n","Epoch 46/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8148 - accuracy: 0.5853 - val_loss: 0.8385 - val_accuracy: 0.5800\n","Epoch 47/100\n","71/71 [==============================] - 1s 10ms/step - loss: 0.8088 - accuracy: 0.5831 - val_loss: 0.8707 - val_accuracy: 0.5453\n","Epoch 48/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8117 - accuracy: 0.5876 - val_loss: 0.8259 - val_accuracy: 0.5867\n","Epoch 49/100\n","71/71 [==============================] - 1s 10ms/step - loss: 0.8097 - accuracy: 0.5840 - val_loss: 0.8775 - val_accuracy: 0.5933\n","Epoch 50/100\n","71/71 [==============================] - 1s 10ms/step - loss: 0.8098 - accuracy: 0.5964 - val_loss: 0.8226 - val_accuracy: 0.6027\n","Epoch 51/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8077 - accuracy: 0.5907 - val_loss: 0.9078 - val_accuracy: 0.5320\n","Epoch 52/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8054 - accuracy: 0.5893 - val_loss: 0.8551 - val_accuracy: 0.5560\n","Epoch 53/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.8025 - accuracy: 0.5924 - val_loss: 0.8218 - val_accuracy: 0.6027\n","Epoch 54/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.8041 - accuracy: 0.5867 - val_loss: 0.8255 - val_accuracy: 0.6133\n","Epoch 55/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7990 - accuracy: 0.5978 - val_loss: 0.8234 - val_accuracy: 0.6133\n","Epoch 56/100\n","71/71 [==============================] - 1s 11ms/step - loss: 0.7953 - accuracy: 0.5951 - val_loss: 0.8502 - val_accuracy: 0.5773\n","Epoch 57/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7963 - accuracy: 0.6058 - val_loss: 0.8488 - val_accuracy: 0.5693\n","Epoch 58/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7968 - accuracy: 0.6027 - val_loss: 0.8406 - val_accuracy: 0.5573\n","Epoch 59/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.7917 - accuracy: 0.6071 - val_loss: 0.8197 - val_accuracy: 0.6053\n","Epoch 60/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7928 - accuracy: 0.5991 - val_loss: 0.8253 - val_accuracy: 0.5867\n","Epoch 61/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7938 - accuracy: 0.5991 - val_loss: 0.8242 - val_accuracy: 0.6013\n","Epoch 62/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7905 - accuracy: 0.6062 - val_loss: 0.9259 - val_accuracy: 0.5213\n","Epoch 63/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7952 - accuracy: 0.5956 - val_loss: 0.8469 - val_accuracy: 0.5920\n","Epoch 64/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7866 - accuracy: 0.6058 - val_loss: 0.8199 - val_accuracy: 0.6053\n","Epoch 65/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7877 - accuracy: 0.6004 - val_loss: 0.8354 - val_accuracy: 0.5773\n","Epoch 66/100\n","71/71 [==============================] - 1s 11ms/step - loss: 0.7847 - accuracy: 0.6027 - val_loss: 0.8532 - val_accuracy: 0.5627\n","Epoch 67/100\n","71/71 [==============================] - 1s 12ms/step - loss: 0.7825 - accuracy: 0.6169 - val_loss: 0.8521 - val_accuracy: 0.5627\n","Epoch 68/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.7805 - accuracy: 0.6044 - val_loss: 0.8313 - val_accuracy: 0.5947\n","Epoch 69/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7862 - accuracy: 0.6004 - val_loss: 0.8383 - val_accuracy: 0.5707\n","Epoch 70/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7808 - accuracy: 0.6058 - val_loss: 0.8608 - val_accuracy: 0.5933\n","Epoch 71/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7756 - accuracy: 0.6129 - val_loss: 0.8426 - val_accuracy: 0.5733\n","Epoch 72/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7777 - accuracy: 0.6164 - val_loss: 0.8501 - val_accuracy: 0.5880\n","Epoch 73/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7744 - accuracy: 0.6147 - val_loss: 0.8236 - val_accuracy: 0.5827\n","Epoch 74/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7741 - accuracy: 0.6191 - val_loss: 0.8255 - val_accuracy: 0.6147\n","Epoch 75/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7732 - accuracy: 0.6156 - val_loss: 0.8360 - val_accuracy: 0.5853\n","Epoch 76/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7742 - accuracy: 0.6111 - val_loss: 0.8214 - val_accuracy: 0.5867\n","Epoch 77/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7670 - accuracy: 0.6196 - val_loss: 0.8421 - val_accuracy: 0.5560\n","Epoch 78/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7698 - accuracy: 0.6147 - val_loss: 0.8259 - val_accuracy: 0.5880\n","Epoch 79/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7693 - accuracy: 0.6142 - val_loss: 0.8928 - val_accuracy: 0.5440\n","Epoch 80/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7687 - accuracy: 0.6053 - val_loss: 0.8172 - val_accuracy: 0.6013\n","Epoch 81/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7658 - accuracy: 0.6160 - val_loss: 0.8454 - val_accuracy: 0.5907\n","Epoch 82/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.7642 - accuracy: 0.6204 - val_loss: 0.8222 - val_accuracy: 0.5920\n","Epoch 83/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7645 - accuracy: 0.6249 - val_loss: 0.8627 - val_accuracy: 0.5627\n","Epoch 84/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7623 - accuracy: 0.6244 - val_loss: 0.8134 - val_accuracy: 0.6187\n","Epoch 85/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.7579 - accuracy: 0.6324 - val_loss: 1.0243 - val_accuracy: 0.4987\n","Epoch 86/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7667 - accuracy: 0.6120 - val_loss: 0.8502 - val_accuracy: 0.5680\n","Epoch 87/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7596 - accuracy: 0.6164 - val_loss: 0.8267 - val_accuracy: 0.5880\n","Epoch 88/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7603 - accuracy: 0.6187 - val_loss: 0.8216 - val_accuracy: 0.5987\n","Epoch 89/100\n","71/71 [==============================] - 1s 9ms/step - loss: 0.7572 - accuracy: 0.6276 - val_loss: 0.8180 - val_accuracy: 0.6053\n","Epoch 90/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7554 - accuracy: 0.6302 - val_loss: 0.8227 - val_accuracy: 0.5920\n","Epoch 91/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7555 - accuracy: 0.6293 - val_loss: 0.8523 - val_accuracy: 0.5893\n","Epoch 92/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7523 - accuracy: 0.6351 - val_loss: 0.8448 - val_accuracy: 0.5627\n","Epoch 93/100\n","71/71 [==============================] - 1s 7ms/step - loss: 0.7487 - accuracy: 0.6347 - val_loss: 0.8903 - val_accuracy: 0.5520\n","Epoch 94/100\n","71/71 [==============================] - 1s 7ms/step - loss: 0.7515 - accuracy: 0.6382 - val_loss: 0.8425 - val_accuracy: 0.5773\n","Epoch 95/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7484 - accuracy: 0.6258 - val_loss: 0.8856 - val_accuracy: 0.5320\n","Epoch 96/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7506 - accuracy: 0.6324 - val_loss: 0.8267 - val_accuracy: 0.5880\n","Epoch 97/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7481 - accuracy: 0.6329 - val_loss: 0.8193 - val_accuracy: 0.6040\n","Epoch 98/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7432 - accuracy: 0.6307 - val_loss: 0.8558 - val_accuracy: 0.5867\n","Epoch 99/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7422 - accuracy: 0.6453 - val_loss: 0.9000 - val_accuracy: 0.5360\n","Epoch 100/100\n","71/71 [==============================] - 1s 8ms/step - loss: 0.7447 - accuracy: 0.6444 - val_loss: 0.8174 - val_accuracy: 0.6120\n"]}],"source":["H = model.fit(x= train_X, y= train_Y, validation_data=(test_X, test_Y), epochs = 100, batch_size = 32)"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Evaluating the model</h2>"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        cats       0.56      0.59      0.57       236\n","        dogs       0.51      0.37      0.43       236\n","       panda       0.70      0.84      0.77       278\n","\n","    accuracy                           0.61       750\n","   macro avg       0.59      0.60      0.59       750\n","weighted avg       0.60      0.61      0.60       750\n","\n"]}],"source":["predictions = model.predict(x=test_X, batch_size = 32)\n","print(classification_report(test_Y.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))\n","\n","#plotting the training loss and accuracy\n","N = np.arange(0, 100)\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy (Simple NN)\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()\n","plt.savefig(\"plot.png\")\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["model.save(\"plot.png\", save_format=\"h5\")\n","f = open(\"model.pickle\", \"wb\")\n","f.write(pickle.dumps(lb))\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":2}
